---
title: "Introduction to Expected Value of Eliminating Causal Ambiguity (EVECA)"
author: "Cory Whitney"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to EVECA}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 7,
  fig.height = 5,
  fig.align = "center"
)

library(evca)
```

# Introduction

## The Problem of Causal Ambiguity

Many decision problems face **causal ambiguity** — uncertainty about which causal model among several competing alternatives correctly describes how interventions affect outcomes. This is different from parameter uncertainty (uncertainty about the magnitude of effects within a known model structure).

For example:
- A policy intervention might work through direct effects, indirect spillovers, or both
- A treatment might operate via mechanism A, mechanism B, or a combination
- An agricultural practice might improve yields through soil health, pest control, or water retention

Traditional value of information (VOI) analysis addresses parameter uncertainty but not structural uncertainty about which causal model is correct.

## Expected Value of Eliminating Causal Ambiguity (EVECA)

**EVECA** extends VOI analysis to handle structural uncertainty. It quantifies the value of knowing which causal model is correct, helping you decide whether to:
- **Act now** under current uncertainty using Bayesian Model Averaging (BMA)
- **Research first** to identify the correct causal model before deciding

### Key Insight

If EVECA is high relative to research costs, invest in resolving model uncertainty. If EVECA is low, the optimal decision is robust across models—proceed without additional research.

# Mathematical Framework

## Setup

Consider:
- **K competing causal models**: M₁, M₂, ..., Mₖ
- **Model probabilities**: p(M₁), p(M₂), ..., p(Mₖ) that sum to 1
- **D decision alternatives**: d₁, d₂, ..., dᴰ
- **Expected utility** EU(dᵢ|Mⱼ) for decision dᵢ under model Mⱼ

## Bayesian Model Averaging (BMA)

Under causal ambiguity, we use BMA to compute expected utility:

$$EU_{BMA}(d) = \sum_{k=1}^K p(M_k) \cdot EU(d|M_k)$$

The optimal decision under BMA is:

$$d^* = \arg\max_d EU_{BMA}(d)$$

## EVECA Calculation

EVECA compares decision-making with and without perfect structural information:

$$EVECA = \underbrace{\sum_{k=1}^K p(M_k) \cdot \max_d EU(d|M_k)}_{\text{With perfect information}} - \underbrace{\max_d \sum_{k=1}^K p(M_k) \cdot EU(d|M_k)}_{\text{BMA (under ambiguity)}}$$

The first term represents expected utility if we knew which model is true (we would choose the optimal decision for that model). The second term is the expected utility of the optimal decision under current ambiguity.

# Basic Example

## Simple Three-Decision, Four-Model Problem

```{r basic_example}
# Define utility matrix: rows = decisions, columns = models
model_utilities <- matrix(
  c(
    8.5, 6.0, 9.0, 7.5,  # Decision 1 utilities under each model
    7.0, 8.5, 5.5, 8.0,  # Decision 2 utilities under each model
    9.0, 7.5, 6.5, 9.5   # Decision 3 utilities under each model
  ),
  nrow = 3, ncol = 4, byrow = TRUE,
  dimnames = list(
    paste("Decision", 1:3),
    paste("Model", 1:4)
  )
)

# Display utility matrix
print(model_utilities)

# Define model probabilities (from data or expert judgment)
model_probs <- c(0.35, 0.30, 0.20, 0.15)
names(model_probs) <- colnames(model_utilities)

print(model_probs)
```

## Compute EVECA

```{r compute_evca}
# Compute EVECA
result <- compute_evca(model_utilities, model_probs)

# Display key results
cat("Optimal decision under BMA:", rownames(model_utilities)[result$optimal_decision_bma], "\n")
cat("Expected utility under BMA:", round(result$optimal_utility_bma, 3), "\n")
cat("Expected utility with perfect info:", round(result$perfect_info_expected_utility, 3), "\n")
cat("EVECA:", round(result$evca, 3), "\n")
```

## Interpretation

```{r interpretation}
# What would we choose under each model?
for (i in 1:length(model_probs)) {
  optimal_under_model <- result$optimal_decisions_per_model[i]
  cat(sprintf(
    "If %s is true (p=%.2f): Choose %s (utility=%.2f)\n",
    names(model_probs)[i],
    model_probs[i],
    rownames(model_utilities)[optimal_under_model],
    result$optimal_utilities_per_model[i]
  ))
}
```

The EVECA of `r round(result$evca, 3)` tells us the maximum we should pay (in utility units) to definitively identify the correct causal model. If research to resolve model ambiguity costs less than this, it's worthwhile.

# Visualization

## Basic EVECA Plot

```{r plot_basic, fig.width=7, fig.height=5}
# Visualize EVECA components
plot_evca(result, title = "EVECA Analysis: Model Ambiguity Value")
```

The gap between the bars represents EVECA — the expected value of eliminating causal ambiguity.

## Utility Heatmap

```{r plot_heatmap, fig.width=8, fig.height=5}
# Visualize utility matrix
evca::plot_utilities_heatmap(
  model_utilities,
  model_probs = model_probs,
  optimal_decision = result$optimal_decision_bma,
  title = "Decision-Model Utility Landscape"
)
```

The yellow border highlights the optimal decision under BMA. Notice how different decisions perform best under different models—this is why EVECA is positive.

## Sensitivity Analysis

```{r plot_sensitivity, fig.width=7, fig.height=5}
# How sensitive is EVECA to our belief about Model 1?
plot_sensitivity(
  model_utilities,
  model_probs,
  vary_model = 1,
  title = "Sensitivity: How EVECA Changes with P(Model 1)"
)
```

This shows how EVECA varies as we become more or less certain about Model 1. The red triangle shows our current probability estimate.

# Multi-Dimensional Outcomes

Often decisions affect multiple outcomes simultaneously (e.g., cost and effectiveness, yield and sustainability). EVECA handles this through multi-attribute utility functions.

## Example with Two Outcome Dimensions

```{r multidim_example}
# Generate example with 2 outcome dimensions
result_multi <- example_evca_multidim(
  n_decisions = 3,
  n_models = 4,
  n_outcomes = 2,
  outcome_weights = c(0.6, 0.4),  # 60% weight on outcome 1, 40% on outcome 2
  seed = 456
)

# View outcome array structure
cat("Outcome array dimensions:", dim(result_multi$model_outcomes), "\n")
cat("Dimensions: decisions x models x outcomes\n\n")

# Show outcomes for Decision 1 under all models
cat("Outcomes for", result_multi$decision_names[1], ":\n")
print(result_multi$model_outcomes[1, , ])
```

## Multi-Attribute Utility

```{r multiattribute}
# The multi-attribute utilities (weighted combination)
cat("Multi-attribute utilities:\n")
print(round(result_multi$model_utilities, 3))

# EVECA result
cat("\nEVECA:", round(result_multi$evca_result$evca, 3), "\n")
cat("Optimal decision:",
    result_multi$decision_names[result_multi$evca_result$optimal_decision_bma], "\n")
```

The outcome weights (0.6, 0.4) determine the trade-off between the two outcome dimensions. Sensitivity analysis could explore how EVECA changes with different weight specifications.

# Using EVECA in Practice

## Workflow

1. **Identify competing causal models**: What are the alternative theories of how your intervention works?

2. **Estimate model probabilities**: Use prior research, pilot data, or expert elicitation

3. **Compute expected utilities**: For each decision under each model, estimate the expected utility

4. **Calculate EVECA**: Use `compute_evca()` to quantify the value of resolving ambiguity

5. **Make decision**:
   - If EVECA < research cost: Choose optimal decision under BMA
   - If EVECA > research cost: Invest in research to identify correct model

## Example Decision Process

```{r decision_process}
# Generate example
ex <- example_evca(n_decisions = 4, n_models = 3, seed = 789)

# Suppose research to identify the correct model costs 2.0 utility units
research_cost <- 2.0

cat("EVECA:", round(ex$evca_result$evca, 3), "\n")
cat("Research cost:", research_cost, "\n\n")

if (ex$evca_result$evca > research_cost) {
  cat("Decision: CONDUCT RESEARCH\n")
  cat("Rationale: Value of resolving ambiguity (", round(ex$evca_result$evca, 3),
      ") exceeds research cost (", research_cost, ")\n")
} else {
  cat("Decision: PROCEED WITH DECISION", ex$decision_names[ex$evca_result$optimal_decision_bma], "\n")
  cat("Rationale: Value of resolving ambiguity (", round(ex$evca_result$evca, 3),
      ") is less than research cost (", research_cost, ")\n")
  cat("Optimal decision under BMA:", ex$decision_names[ex$evca_result$optimal_decision_bma], "\n")
}
```

# Advanced Topics

## Risk Aversion

By default, EVECA assumes risk-neutral utility. You can incorporate risk preferences:

```{r risk_aversion}
# Assume outcomes (not utilities) in model_utilities
outcomes <- matrix(
  c(100, 80, 120, 90,
    70, 110, 60, 95,
    115, 95, 75, 105),
  nrow = 3, ncol = 4, byrow = TRUE
)

# Risk-neutral (identity utility)
result_neutral <- compute_evca(outcomes, model_probs)

# Risk-averse (exponential utility with risk aversion coefficient 0.02)
result_averse <- compute_evca(
  outcomes,
  model_probs,
  utility_function = function(x) -exp(-0.02 * x)
)

cat("EVECA (risk-neutral):", round(result_neutral$evca, 3), "\n")
cat("EVECA (risk-averse):", round(result_averse$evca, 3), "\n")
```

Risk aversion typically increases EVECA because uncertainty is more costly when you're risk-averse.

## Relationship to EVPI

EVECA addresses structural uncertainty (which model?), while EVPI addresses parameter uncertainty (what are the exact parameter values?). In problems with both types of uncertainty:

$$\text{Total VOI} \approx \text{EVPI}_{parameters} + \text{EVECA}_{structure}$$

In practice, you might first compute EVECA to see if resolving structural uncertainty is valuable, then compute EVPI for parameters within the most probable model.

# Conclusion

EVECA provides a rigorous framework for:
- **Quantifying** the value of resolving model uncertainty
- **Prioritizing** research investments
- **Making robust decisions** under causal ambiguity
- **Combining** information from multiple competing theories

Key takeaways:
- High EVECA → Research to identify correct model is valuable
- Low EVECA → Optimal decision is robust; proceed with BMA
- EVECA integrates Bayesian model averaging with decision theory
- Framework extends to multi-dimensional outcomes and risk preferences

# Further Reading

For more details on the theoretical foundations and applications:
- Bayesian Model Averaging: Hoeting et al. (1999)
- Value of Information: Claxton (1999), Yokota & Thompson (2004)
- Decision Theory under Model Uncertainty: Brock et al. (2003)

# Session Info

```{r session_info}
sessionInfo()
```
